{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T09:46:05.424917Z",
     "start_time": "2025-01-17T09:46:03.536653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import DataLoader\n",
    "import penman\n",
    "from transition_amr_parser.parse import AMRParser"
   ],
   "id": "c1808f877bd9876e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai4learning/cenv_x86/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T09:48:27.285863Z",
     "start_time": "2025-01-17T09:46:09.455325Z"
    }
   },
   "source": [
    "\n",
    "parser = AMRParser.from_pretrained('AMR3-structbart-L')\n",
    "\n",
    "def AMR(text):\n",
    "    # Download and save a model named AMR3.0 to cache\n",
    "    tokens, positions = parser.tokenize(text)\n",
    "    \n",
    "    # Use parse_sentence() for single sentences or parse_sentences() for a batch\n",
    "    annotations, machines = parser.parse_sentence(tokens)\n",
    "    \n",
    "    # Print Penman notation\n",
    "    return annotations\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from cache /home/ai4learning/.cache/torch/DATA/AMR3.0/models/amr3.0-structured-bart-large-neur-al/seed42/checkpoint_wiki.smatch_top5-avg.pt\n",
      "| [en] dictionary: 46088 types\n",
      "| [actions_nopos] dictionary: 16544 types\n",
      "----------loading pretrained bart.large model ----------\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 110] Connection timed out>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTimeoutError\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/urllib/request.py:1354\u001B[0m, in \u001B[0;36mAbstractHTTPHandler.do_open\u001B[0;34m(self, http_class, req, **http_conn_args)\u001B[0m\n\u001B[1;32m   1353\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1354\u001B[0m     \u001B[43mh\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1355\u001B[0m \u001B[43m              \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhas_header\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mTransfer-encoding\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1356\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err: \u001B[38;5;66;03m# timeout error\u001B[39;00m\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/http/client.py:1256\u001B[0m, in \u001B[0;36mHTTPConnection.request\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[1;32m   1255\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1256\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/http/client.py:1302\u001B[0m, in \u001B[0;36mHTTPConnection._send_request\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[1;32m   1301\u001B[0m     body \u001B[38;5;241m=\u001B[39m _encode(body, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbody\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m-> 1302\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mendheaders\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/http/client.py:1251\u001B[0m, in \u001B[0;36mHTTPConnection.endheaders\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[1;32m   1250\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CannotSendHeader()\n\u001B[0;32m-> 1251\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/http/client.py:1011\u001B[0m, in \u001B[0;36mHTTPConnection._send_output\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[1;32m   1010\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_buffer[:]\n\u001B[0;32m-> 1011\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1013\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m message_body \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1014\u001B[0m \n\u001B[1;32m   1015\u001B[0m     \u001B[38;5;66;03m# create a consistent interface to message_body\u001B[39;00m\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/http/client.py:951\u001B[0m, in \u001B[0;36mHTTPConnection.send\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    950\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_open:\n\u001B[0;32m--> 951\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    952\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/http/client.py:1418\u001B[0m, in \u001B[0;36mHTTPSConnection.connect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1416\u001B[0m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnect to a host on a given (SSL) port.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1418\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1420\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tunnel_host:\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/http/client.py:922\u001B[0m, in \u001B[0;36mHTTPConnection.connect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    921\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 922\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_connection\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    923\u001B[0m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhost\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mport\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msource_address\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    924\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock\u001B[38;5;241m.\u001B[39msetsockopt(socket\u001B[38;5;241m.\u001B[39mIPPROTO_TCP, socket\u001B[38;5;241m.\u001B[39mTCP_NODELAY, \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/socket.py:820\u001B[0m, in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address)\u001B[0m\n\u001B[1;32m    819\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 820\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[1;32m    821\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    822\u001B[0m     \u001B[38;5;66;03m# Break explicitly a reference cycle\u001B[39;00m\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/socket.py:808\u001B[0m, in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address)\u001B[0m\n\u001B[1;32m    807\u001B[0m     sock\u001B[38;5;241m.\u001B[39mbind(source_address)\n\u001B[0;32m--> 808\u001B[0m \u001B[43msock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43msa\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    809\u001B[0m \u001B[38;5;66;03m# Break explicitly a reference cycle\u001B[39;00m\n",
      "\u001B[0;31mTimeoutError\u001B[0m: [Errno 110] Connection timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mURLError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mAMRParser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mAMR3-structbart-L\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mAMR\u001B[39m(text):\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;66;03m# Download and save a model named AMR3.0 to cache\u001B[39;00m\n\u001B[1;32m      5\u001B[0m     tokens, positions \u001B[38;5;241m=\u001B[39m parser\u001B[38;5;241m.\u001B[39mtokenize(text)\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/site-packages/transition_amr_parser/parse.py:734\u001B[0m, in \u001B[0;36mAMRParser.from_pretrained\u001B[0;34m(cls, model_name, dict_dir, roberta_cache_path, fp16, inspector, beam, nbest, num_samples, sampling_topp, temperature)\u001B[0m\n\u001B[1;32m    732\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    733\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mload from cache \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcheckpoint_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 734\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdict_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    735\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mroberta_cache_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfp16\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minspector\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    736\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mbeam\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnbest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msampling_topp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    737\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/site-packages/transition_amr_parser/parse.py:785\u001B[0m, in \u001B[0;36mAMRParser.from_checkpoint\u001B[0;34m(cls, checkpoint, dict_dir, roberta_cache_path, fp16, inspector, beam, nbest, num_samples, sampling_topp, temperature)\u001B[0m\n\u001B[1;32m    783\u001B[0m     \u001B[38;5;66;03m# otherwise, the default dict folder is read from the model args\u001B[39;00m\n\u001B[1;32m    784\u001B[0m use_cuda \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args\u001B[38;5;241m.\u001B[39mcpu\n\u001B[0;32m--> 785\u001B[0m models, model_args, task \u001B[38;5;241m=\u001B[39m \u001B[43mload_models_and_task\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    786\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_cuda\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\n\u001B[1;32m    787\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    788\u001B[0m \u001B[38;5;66;03m# overload some arguments\u001B[39;00m\n\u001B[1;32m    789\u001B[0m \u001B[38;5;66;03m# SequenceGenerator args: sampling_topk sampling_topp temperature\u001B[39;00m\n\u001B[1;32m    790\u001B[0m args\u001B[38;5;241m.\u001B[39mbeam \u001B[38;5;241m=\u001B[39m beam\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/site-packages/transition_amr_parser/parse.py:279\u001B[0m, in \u001B[0;36mload_models_and_task\u001B[0;34m(args, use_cuda, task)\u001B[0m\n\u001B[1;32m    268\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Fairseq load from task method\u001B[39;00m\n\u001B[1;32m    269\u001B[0m \n\u001B[1;32m    270\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    276\u001B[0m \u001B[38;5;124;03m    _type_: _description_\u001B[39;00m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    278\u001B[0m \u001B[38;5;66;03m# if `task` is not provided, it will be from the saved model args\u001B[39;00m\n\u001B[0;32m--> 279\u001B[0m models, model_args, task \u001B[38;5;241m=\u001B[39m \u001B[43mcheckpoint_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model_ensemble_and_task\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m:\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[43m    \u001B[49m\u001B[43marg_overrides\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_overrides\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    282\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;66;03m# Optimize ensemble for generation\u001B[39;00m\n\u001B[1;32m    285\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model \u001B[38;5;129;01min\u001B[39;00m models:\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/site-packages/fairseq/checkpoint_utils.py:283\u001B[0m, in \u001B[0;36mload_model_ensemble_and_task\u001B[0;34m(filenames, arg_overrides, task, strict, suffix, num_shards)\u001B[0m\n\u001B[1;32m    281\u001B[0m args \u001B[38;5;241m=\u001B[39m state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124margs\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    282\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m task \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 283\u001B[0m     task \u001B[38;5;241m=\u001B[39m \u001B[43mtasks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup_task\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[38;5;66;03m# build model for ensemble\u001B[39;00m\n\u001B[1;32m    286\u001B[0m model \u001B[38;5;241m=\u001B[39m task\u001B[38;5;241m.\u001B[39mbuild_model(args)\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/site-packages/fairseq/tasks/__init__.py:28\u001B[0m, in \u001B[0;36msetup_task\u001B[0;34m(task_cfg, **kwargs)\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(task_cfg, DictConfig):\n\u001B[1;32m     27\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m TASK_REGISTRY[task_cfg\u001B[38;5;241m.\u001B[39m_name]\u001B[38;5;241m.\u001B[39msetup_task(task_cfg, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m---> 28\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mTASK_REGISTRY\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtask_cfg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtask\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup_task\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtask_cfg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/site-packages/fairseq_ext/tasks/amr_action_pointer_bart.py:280\u001B[0m, in \u001B[0;36mAMRActionPointerBARTParsingTask.setup_task\u001B[0;34m(cls, args, **kwargs)\u001B[0m\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbart_large\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m args\u001B[38;5;241m.\u001B[39march:\n\u001B[1;32m    279\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloading pretrained bart.large model \u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m10\u001B[39m)\n\u001B[0;32m--> 280\u001B[0m     bart \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhub\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpytorch/fairseq\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbart.large\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    281\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minitialize_with_watbart\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m args\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m\u001B[38;5;241m.\u001B[39mkeys() \u001B[38;5;129;01mand\u001B[39;00m args\u001B[38;5;241m.\u001B[39minitialize_with_watbart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    282\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/site-packages/torch/hub.py:539\u001B[0m, in \u001B[0;36mload\u001B[0;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001B[0m\n\u001B[1;32m    535\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    536\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUnknown source: \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msource\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m. Allowed values: \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgithub\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m | \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlocal\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m source \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgithub\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 539\u001B[0m     repo_or_dir \u001B[38;5;241m=\u001B[39m \u001B[43m_get_cache_or_reload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrepo_or_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforce_reload\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrust_repo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mload\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    540\u001B[0m \u001B[43m                                       \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskip_validation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskip_validation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    542\u001B[0m model \u001B[38;5;241m=\u001B[39m _load_local(repo_or_dir, model, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    543\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/site-packages/torch/hub.py:180\u001B[0m, in \u001B[0;36m_get_cache_or_reload\u001B[0;34m(github, force_reload, trust_repo, calling_fn, verbose, skip_validation)\u001B[0m\n\u001B[1;32m    178\u001B[0m     os\u001B[38;5;241m.\u001B[39mmakedirs(hub_dir)\n\u001B[1;32m    179\u001B[0m \u001B[38;5;66;03m# Parse github repo information\u001B[39;00m\n\u001B[0;32m--> 180\u001B[0m repo_owner, repo_name, ref \u001B[38;5;241m=\u001B[39m \u001B[43m_parse_repo_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgithub\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[38;5;66;03m# Github allows branch name with slash '/',\u001B[39;00m\n\u001B[1;32m    182\u001B[0m \u001B[38;5;66;03m# this causes confusion with path on both Linux and Windows.\u001B[39;00m\n\u001B[1;32m    183\u001B[0m \u001B[38;5;66;03m# Backslash is not allowed in Github branch name so no need to\u001B[39;00m\n\u001B[1;32m    184\u001B[0m \u001B[38;5;66;03m# to worry about it.\u001B[39;00m\n\u001B[1;32m    185\u001B[0m normalized_br \u001B[38;5;241m=\u001B[39m ref\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/site-packages/torch/hub.py:134\u001B[0m, in \u001B[0;36m_parse_repo_info\u001B[0;34m(github)\u001B[0m\n\u001B[1;32m    129\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ref \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    130\u001B[0m     \u001B[38;5;66;03m# The ref wasn't specified by the user, so we need to figure out the\u001B[39;00m\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;66;03m# default branch: main or master. Our assumption is that if main exists\u001B[39;00m\n\u001B[1;32m    132\u001B[0m     \u001B[38;5;66;03m# then it's the default branch, otherwise it's master.\u001B[39;00m\n\u001B[1;32m    133\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 134\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhttps://github.com/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mrepo_owner\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mrepo_name\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/tree/main/\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    135\u001B[0m             ref \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmain\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m HTTPError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/urllib/request.py:222\u001B[0m, in \u001B[0;36murlopen\u001B[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001B[0m\n\u001B[1;32m    220\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    221\u001B[0m     opener \u001B[38;5;241m=\u001B[39m _opener\n\u001B[0;32m--> 222\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mopener\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/urllib/request.py:525\u001B[0m, in \u001B[0;36mOpenerDirector.open\u001B[0;34m(self, fullurl, data, timeout)\u001B[0m\n\u001B[1;32m    522\u001B[0m     req \u001B[38;5;241m=\u001B[39m meth(req)\n\u001B[1;32m    524\u001B[0m sys\u001B[38;5;241m.\u001B[39maudit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124murllib.Request\u001B[39m\u001B[38;5;124m'\u001B[39m, req\u001B[38;5;241m.\u001B[39mfull_url, req\u001B[38;5;241m.\u001B[39mdata, req\u001B[38;5;241m.\u001B[39mheaders, req\u001B[38;5;241m.\u001B[39mget_method())\n\u001B[0;32m--> 525\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[38;5;66;03m# post-process response\u001B[39;00m\n\u001B[1;32m    528\u001B[0m meth_name \u001B[38;5;241m=\u001B[39m protocol\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_response\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/urllib/request.py:542\u001B[0m, in \u001B[0;36mOpenerDirector._open\u001B[0;34m(self, req, data)\u001B[0m\n\u001B[1;32m    539\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[1;32m    541\u001B[0m protocol \u001B[38;5;241m=\u001B[39m req\u001B[38;5;241m.\u001B[39mtype\n\u001B[0;32m--> 542\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_chain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_open\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\n\u001B[1;32m    543\u001B[0m \u001B[43m                          \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m_open\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    544\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result:\n\u001B[1;32m    545\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/urllib/request.py:502\u001B[0m, in \u001B[0;36mOpenerDirector._call_chain\u001B[0;34m(self, chain, kind, meth_name, *args)\u001B[0m\n\u001B[1;32m    500\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m handler \u001B[38;5;129;01min\u001B[39;00m handlers:\n\u001B[1;32m    501\u001B[0m     func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(handler, meth_name)\n\u001B[0;32m--> 502\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    503\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    504\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/urllib/request.py:1397\u001B[0m, in \u001B[0;36mHTTPSHandler.https_open\u001B[0;34m(self, req)\u001B[0m\n\u001B[1;32m   1396\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhttps_open\u001B[39m(\u001B[38;5;28mself\u001B[39m, req):\n\u001B[0;32m-> 1397\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhttp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mHTTPSConnection\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1398\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcontext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_context\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_hostname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/urllib/request.py:1357\u001B[0m, in \u001B[0;36mAbstractHTTPHandler.do_open\u001B[0;34m(self, http_class, req, **http_conn_args)\u001B[0m\n\u001B[1;32m   1354\u001B[0m         h\u001B[38;5;241m.\u001B[39mrequest(req\u001B[38;5;241m.\u001B[39mget_method(), req\u001B[38;5;241m.\u001B[39mselector, req\u001B[38;5;241m.\u001B[39mdata, headers,\n\u001B[1;32m   1355\u001B[0m                   encode_chunked\u001B[38;5;241m=\u001B[39mreq\u001B[38;5;241m.\u001B[39mhas_header(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTransfer-encoding\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m   1356\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err: \u001B[38;5;66;03m# timeout error\u001B[39;00m\n\u001B[0;32m-> 1357\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m URLError(err)\n\u001B[1;32m   1358\u001B[0m     r \u001B[38;5;241m=\u001B[39m h\u001B[38;5;241m.\u001B[39mgetresponse()\n\u001B[1;32m   1359\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n",
      "\u001B[0;31mURLError\u001B[0m: <urlopen error [Errno 110] Connection timed out>"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T01:18:43.657050Z",
     "start_time": "2024-12-26T01:18:43.647185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_amr_to_graph(amr_text):\n",
    "    \"\"\"\n",
    "    将 AMR 图字符串解析为 PyTorch Geometric 数据对象。\n",
    "    \"\"\"\n",
    "    # 使用 penman 解析 AMR\n",
    "    graph = penman.decode(amr_text)\n",
    "    \n",
    "    # 提取节点\n",
    "    nodes = []\n",
    "    for instance in graph.instances():\n",
    "        node_id, concept = instance[0], instance[1]\n",
    "        nodes.append((node_id, concept))\n",
    "\n",
    "    # 提取边\n",
    "    edges = []\n",
    "    for edge in graph.edges():\n",
    "        source, role, target = edge\n",
    "        edges.append((source, target, role))\n",
    "\n",
    "    # 构造节点索引映射\n",
    "    node_to_idx = {node[0]: i for i, node in enumerate(nodes)}\n",
    "\n",
    "    # 转化为 PyTorch Geometric 格式\n",
    "    edge_index = torch.tensor([[node_to_idx[src], node_to_idx[tgt]] for src, tgt, _ in edges], dtype=torch.long).t()\n",
    "\n",
    "    # 边的特征（关系类型编码为整数）\n",
    "    edge_attr = [role for _, _, role in edges]\n",
    "    edge_attr = torch.tensor([hash(role) % 1000 for role in edge_attr], dtype=torch.long)  # 简单的哈希映射\n",
    "\n",
    "    # 节点特征（用概念字符串的哈希值表示）\n",
    "    x = torch.tensor([[hash(concept) % 1000] for _, concept in nodes], dtype=torch.float)\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)"
   ],
   "id": "246b55ad885e2f2c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T01:22:51.876718Z",
     "start_time": "2024-12-26T01:22:51.775312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "graphs=[]\n",
    "amr_texts=[\"I have a question\",\"I want to konw how to do it\"]\n",
    "graphs.append(parse_amr_to_graph(amr_text) for amr_text in amr_texts)\n",
    "data_list = [parse_amr_to_graph(amr_text) for amr_text in amr_texts]\n",
    "\n",
    "\n"
   ],
   "id": "82bfa29f9745e5d6",
   "outputs": [
    {
     "ename": "DecodeError",
     "evalue": "\n  line 1\n    I have a question\n    ^\nDecodeError: Expected: LPAREN",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mDecodeError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m amr_texts\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mI have a question\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mI want to konw how to do it\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m      3\u001B[0m graphs\u001B[38;5;241m.\u001B[39mappend(parse_amr_to_graph(amr_text) \u001B[38;5;28;01mfor\u001B[39;00m amr_text \u001B[38;5;129;01min\u001B[39;00m amr_texts)\n\u001B[0;32m----> 4\u001B[0m data_list \u001B[38;5;241m=\u001B[39m [parse_amr_to_graph(amr_text) \u001B[38;5;28;01mfor\u001B[39;00m amr_text \u001B[38;5;129;01min\u001B[39;00m amr_texts]\n",
      "Cell \u001B[0;32mIn[16], line 4\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m      2\u001B[0m amr_texts\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mI have a question\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mI want to konw how to do it\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m      3\u001B[0m graphs\u001B[38;5;241m.\u001B[39mappend(parse_amr_to_graph(amr_text) \u001B[38;5;28;01mfor\u001B[39;00m amr_text \u001B[38;5;129;01min\u001B[39;00m amr_texts)\n\u001B[0;32m----> 4\u001B[0m data_list \u001B[38;5;241m=\u001B[39m [\u001B[43mparse_amr_to_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamr_text\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m amr_text \u001B[38;5;129;01min\u001B[39;00m amr_texts]\n",
      "Cell \u001B[0;32mIn[11], line 6\u001B[0m, in \u001B[0;36mparse_amr_to_graph\u001B[0;34m(amr_text)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m将 AMR 图字符串解析为 PyTorch Geometric 数据对象。\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# 使用 penman 解析 AMR\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m graph \u001B[38;5;241m=\u001B[39m \u001B[43mpenman\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamr_text\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# 提取节点\u001B[39;00m\n\u001B[1;32m      9\u001B[0m nodes \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/site-packages/penman/codec.py:192\u001B[0m, in \u001B[0;36m_decode\u001B[0;34m(s, model)\u001B[0m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;124;03mDeserialize PENMAN-serialized *s* into its Graph object\u001B[39;00m\n\u001B[1;32m    179\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    189\u001B[0m \n\u001B[1;32m    190\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    191\u001B[0m codec \u001B[38;5;241m=\u001B[39m PENMANCodec(model\u001B[38;5;241m=\u001B[39mmodel)\n\u001B[0;32m--> 192\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcodec\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/site-packages/penman/codec.py:57\u001B[0m, in \u001B[0;36mPENMANCodec.decode\u001B[0;34m(self, s)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode\u001B[39m(\u001B[38;5;28mself\u001B[39m, s: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Graph:\n\u001B[1;32m     44\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;124;03m    Deserialize PENMAN-notation string *s* into its Graph object.\u001B[39;00m\n\u001B[1;32m     46\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;124;03m        <Graph object (top=b) at ...>\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 57\u001B[0m     tree \u001B[38;5;241m=\u001B[39m \u001B[43mparse\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     58\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m layout\u001B[38;5;241m.\u001B[39minterpret(tree, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel)\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/site-packages/penman/_parse.py:34\u001B[0m, in \u001B[0;36mparse\u001B[0;34m(s)\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;124;03mParse PENMAN-notation string *s* into its tree structure.\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     31\u001B[0m \n\u001B[1;32m     32\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     33\u001B[0m tokens \u001B[38;5;241m=\u001B[39m lex(s, pattern\u001B[38;5;241m=\u001B[39mPENMAN_RE)\n\u001B[0;32m---> 34\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_parse\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokens\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/site-packages/penman/_parse.py:81\u001B[0m, in \u001B[0;36m_parse\u001B[0;34m(tokens)\u001B[0m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_parse\u001B[39m(tokens: TokenIterator) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tree:\n\u001B[1;32m     80\u001B[0m     metadata \u001B[38;5;241m=\u001B[39m _parse_comments(tokens)\n\u001B[0;32m---> 81\u001B[0m     node \u001B[38;5;241m=\u001B[39m \u001B[43m_parse_node\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokens\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     82\u001B[0m     tree \u001B[38;5;241m=\u001B[39m Tree(node, metadata\u001B[38;5;241m=\u001B[39mmetadata)\n\u001B[1;32m     83\u001B[0m     logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mParsed: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m, tree)\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/site-packages/penman/_parse.py:110\u001B[0m, in \u001B[0;36m_parse_node\u001B[0;34m(tokens)\u001B[0m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_parse_node\u001B[39m(tokens: TokenIterator):\n\u001B[1;32m    103\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;124;03m    Parse a PENMAN node from *tokens*.\u001B[39;00m\n\u001B[1;32m    105\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    108\u001B[0m \u001B[38;5;124;03m        Node := '(' ID ('/' Concept)? Edge* ')'\u001B[39;00m\n\u001B[1;32m    109\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 110\u001B[0m     \u001B[43mtokens\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexpect\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mLPAREN\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    112\u001B[0m     var \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    113\u001B[0m     concept: Union[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m]\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/site-packages/penman/_lexer.py:140\u001B[0m, in \u001B[0;36mTokenIterator.expect\u001B[0;34m(self, *choices)\u001B[0m\n\u001B[1;32m    138\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUnexpected end of input\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m token\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m choices:\n\u001B[0;32m--> 140\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39merror(\n\u001B[1;32m    141\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExpected: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(choices)), token\u001B[38;5;241m=\u001B[39mtoken\n\u001B[1;32m    142\u001B[0m     )\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m token\n",
      "\u001B[0;31mDecodeError\u001B[0m: \n  line 1\n    I have a question\n    ^\nDecodeError: Expected: LPAREN"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T01:23:40.374195Z",
     "start_time": "2024-12-26T01:23:40.367155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "graphs_gen = (parse_amr_to_graph(amr_text) for amr_text in amr_texts)\n",
    "\n",
    "# 通过 list 强制执行生成器\n",
    "try:\n",
    "    graphs_list = list(graphs_gen)\n",
    "    print(\"Generator executed successfully:\", graphs_list)\n",
    "except Exception as e:\n",
    "    print(\"Error occurred during generator execution:\", e)\n"
   ],
   "id": "e6f7e3328d965695",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred during generator execution: \n",
      "  line 1\n",
      "    I have a question\n",
      "    ^\n",
      "DecodeError: Expected: LPAREN\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T01:20:51.326128Z",
     "start_time": "2024-12-26T01:20:51.245521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 2\n",
    "loader = DataLoader(graphs, batch_size=batch_size, shuffle=True)\n",
    "for batch in loader:\n",
    "    print(\"Batch Data:\")\n",
    "    print(\"Node Features (x):\", batch.x)\n",
    "    print(\"Edge Index (edge_index):\", batch.edge_index)\n",
    "    print(\"Edge Attributes (edge_attr):\", batch.edge_attr)\n",
    "    print(\"Batch Mapping:\", batch.batch) "
   ],
   "id": "497081a6b962cdfb",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DataLoader found invalid type: '<class 'generator'>'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m      2\u001B[0m loader \u001B[38;5;241m=\u001B[39m DataLoader(graphs, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m loader:\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBatch Data:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNode Features (x):\u001B[39m\u001B[38;5;124m\"\u001B[39m, batch\u001B[38;5;241m.\u001B[39mx)\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    626\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 628\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    631\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    632\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/site-packages/torch/utils/data/dataloader.py:671\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    669\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    670\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 671\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    672\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    673\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:61\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     60\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[0;32m---> 61\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/cenv_x86/lib/python3.8/site-packages/torch_geometric/loader/dataloader.py:49\u001B[0m, in \u001B[0;36mCollater.__call__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, Sequence) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m(s) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch)]\n\u001B[0;32m---> 49\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader found invalid type: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(elem)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: DataLoader found invalid type: '<class 'generator'>'"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T01:08:25.424820Z",
     "start_time": "2024-12-26T01:08:25.412543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataloader = DataLoader(graphs, batch_size=16, shuffle=True)\n",
    "for batch in dataloader:\n",
    "    # 节点特征矩阵、边索引、批次信息\n",
    "    x = batch.x\n",
    "    edge_index = batch.edge_index\n",
    "    batch_info = batch.batch  # 用于全局池化时标记图的归属\n",
    "    print(x)\n",
    "    print(batch_info)\n",
    "    print(edge_index)\n"
   ],
   "id": "f07e2705f4c37bd0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Graph object (top=q) at 125240369641264>, <Graph object (top=c) at 125238959291408>]\n",
      "tensor([], dtype=torch.int64)\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai4learning/cenv_x86/lib/python3.8/site-packages/torch_geometric/data/storage.py:452: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'x'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T01:38:22.409314Z",
     "start_time": "2024-12-26T01:38:22.396761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import penman\n",
    "import numpy as np\n",
    "def graph_struct(amr_text):\n",
    "    graph = penman.decode(amr_text)\n",
    "    \n",
    "    # 提取节点和边\n",
    "    nodes = [inst[0] for inst in graph.instances()]  # 获取所有节点ID\n",
    "    edges = graph.edges()  # 获取所有边（关系）\n",
    "    num_nodes = len(nodes)\n",
    "    adj_matrix = np.zeros((num_nodes, num_nodes))\n",
    "    x = torch.eye(num_nodes)  # 独热向量表示的节点特征\n",
    "\n",
    "    node_to_index = {node: i for i, node in enumerate(nodes)}  # 为每个节点分配索引\n",
    "    for edge in edges:\n",
    "        src, rel, tgt = edge\n",
    "        src_idx = node_to_index[src]\n",
    "        tgt_idx = node_to_index[tgt]\n",
    "        adj_matrix[src_idx, tgt_idx] = 1 \n",
    "    \n",
    "    # 定义边索引\n",
    "    edge_index = torch.tensor([[node_to_index[src], node_to_index[tgt]] for src, _, tgt in edges]).t().contiguous()\n",
    "    \n",
    "    # 构造图数据\n",
    "    data = Data(x=x, edge_index=edge_index)\n"
   ],
   "id": "bd71f9e4b304fd9e",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "# 创建 PyTorch Geometric 数据对象\n",
    "graph_data_list\n",
    "\n",
    "# 动态批量化\n",
    "batched_graph = Batch.from_data_list(graph_data_list)\n",
    "\n",
    "print(\"Batched Graph:\", batched_graph)\n"
   ],
   "id": "bc1c263715243044"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T02:06:46.913979Z",
     "start_time": "2024-12-26T02:06:46.891978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def amr_to_graph(amr_text, feature_dim=16):\n",
    "    \"\"\"\n",
    "    将 AMR 文本解析为 PyTorch Geometric 的图数据格式，并统一节点特征维度。\n",
    "    \"\"\"\n",
    "    # 使用 Penman 解析 AMR 文本\n",
    "    graph = penman.decode(amr_text)\n",
    "    \n",
    "    # 提取节点和边\n",
    "    nodes = [instance[0] for instance in graph.instances()]  # 获取节点ID\n",
    "    edges = graph.edges()  # 获取边信息（src, rel, tgt）\n",
    "    \n",
    "    # 为每个节点创建固定维度的特征（随机初始化或零向量）\n",
    "    num_nodes = len(nodes)\n",
    "    node_features = torch.zeros((num_nodes, feature_dim))  # 这里为零初始化\n",
    "    # 可选：为每个节点分配唯一特征（如词嵌入、随机值）\n",
    "    node_features = torch.rand((num_nodes, feature_dim))  # 随机初始化\n",
    "    \n",
    "    # 将边转换为 PyTorch Geometric 的 edge_index 格式\n",
    "    node_to_index = {node: i for i, node in enumerate(nodes)}\n",
    "    edge_index = []\n",
    "    for src, rel, tgt in edges:\n",
    "        if src in node_to_index and tgt in node_to_index:\n",
    "            edge_index.append([node_to_index[src], node_to_index[tgt]])\n",
    "    \n",
    "    # 转换为 PyTorch 张量\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous() if edge_index else torch.empty((2, 0), dtype=torch.long)\n",
    "    \n",
    "    # 返回 PyTorch Geometric 的 Data 对象\n",
    "    return Data(x=node_features, edge_index=edge_index)\n",
    "# 示例 AMR 文本列表\n",
    "\n"
   ],
   "id": "dee04078f93b02d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batched Graph:\n",
      "DataBatch(x=[12, 16], edge_index=[2, 10], batch=[12], ptr=[4])\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T02:15:15.934656Z",
     "start_time": "2024-12-26T02:15:15.479037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "amr_texts=[]\n",
    "amr_texts.append(AMR(\"I have a question\"))\n",
    "amr_texts.append(AMR(\"I want to konw how to do it\"))\n",
    "\n",
    "\n",
    "# 将 AMR 文本解析为 PyTorch Geometric 图数据\n",
    "feature_dim = 16  # 固定特征维度\n",
    "graph_list = [amr_to_graph(amr_text, feature_dim=feature_dim) for amr_text in amr_texts]\n",
    "\n",
    "# 使用 PyTorch Geometric 的 Batch 进行批处理\n",
    "batched_graph = Batch.from_data_list(graph_list)\n",
    "\n",
    "# 打印批处理结果\n",
    "print(\"Batched Graph:\")\n",
    "print(batched_graph)"
   ],
   "id": "e1734d21f8d6121c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 1\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "decoding: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on batch size: 1\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "decoding: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batched Graph:\n",
      "DataBatch(x=[8, 16], edge_index=[2, 8], batch=[8], ptr=[3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T02:55:06.210523Z",
     "start_time": "2024-12-26T02:55:06.188095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class GraphEncoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GraphEncoder, self).__init__()\n",
    "        # 图卷积层\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        # 全局池化后映射到最终嵌入维度\n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        输入批处理后的图数据 (Batch 对象)，输出图嵌入。\n",
    "        \"\"\"\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # 图卷积层 1\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)  # 激活函数\n",
    "        # 图卷积层 2\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # 图级别嵌入 (使用全局池化)\n",
    "        x = global_mean_pool(x, batch)  # 维度为 [num_graphs, hidden_dim]\n",
    "        \n",
    "        # 最终嵌入映射\n",
    "        x = self.fc(x)  # 维度为 [num_graphs, output_dim]\n",
    "        return x\n",
    "\n",
    "# 定义模型参数\n",
    "input_dim = 16  # 输入特征维度，与之前 amr_to_graph 一致\n",
    "hidden_dim = 32  # 隐藏层维度\n",
    "output_dim = 64  # 输出嵌入维度（最终图表示）\n",
    "\n",
    "# 初始化模型\n",
    "model = GraphEncoder(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)\n",
    "\n",
    "# 假设批处理后的图数据 batched_graph\n",
    "output = model(batched_graph)  # 输出图嵌入\n",
    "\n",
    "print(\"Encoded Graph Embeddings:\", output.shape)  # [num_graphs, output_dim]\n"
   ],
   "id": "aca0ec4a59a457cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Graph Embeddings: torch.Size([2, 64])\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T12:45:12.953043Z",
     "start_time": "2024-12-26T12:45:12.925108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "\n",
    "# 创建 teacher 图和 student 图的不同数据\n",
    "teacher_graph1 = Data(x=torch.tensor([[1], [2], [3]]), edge_index=torch.tensor([[0, 1, 2], [1, 2, 0]]))\n",
    "student_graph1 = Data(x=torch.tensor([[4], [5]]), edge_index=torch.tensor([[0, 1], [1, 0]]))\n",
    "\n",
    "teacher_graph2 = Data(x=torch.tensor([[6], [7]]), edge_index=torch.tensor([[0, 1], [1, 0]]))\n",
    "student_graph2 = Data(x=torch.tensor([[8], [9], [10]]), edge_index=torch.tensor([[0, 2], [2, 1]]))\n",
    "\n",
    "teacher_graph3 = Data(x=torch.tensor([[11], [12], [13], [14]]), edge_index=torch.tensor([[0, 1, 2, 3], [1, 2, 3, 0]]))\n",
    "student_graph3 = Data(x=torch.tensor([[15], [16], [17]]), edge_index=torch.tensor([[0, 1, 2], [1, 2, 0]]))\n",
    "\n",
    "# 创建 (teacher, student) 图对列表\n",
    "graph_pairs = [\n",
    "    (teacher_graph1, student_graph1),\n",
    "    (teacher_graph2, student_graph2),\n",
    "    (teacher_graph3, student_graph3),\n",
    "]\n",
    "\n",
    "# 自定义 collate_fn 函数\n",
    "def custom_collate_fn(batch):\n",
    "    # 提取 teacher 和 student 图\n",
    "    teacher_graphs = [pair[0] for pair in batch]\n",
    "    student_graphs = [pair[1] for pair in batch]\n",
    "\n",
    "    # 合并为 Batch\n",
    "    teacher_batch = Batch.from_data_list(teacher_graphs)\n",
    "    student_batch = Batch.from_data_list(student_graphs)\n",
    "\n",
    "    # 返回字典\n",
    "    return {\"teacher\": teacher_batch, \"student\": student_batch}\n",
    "\n",
    "# 创建 DataLoader，batch_size=2\n",
    "loader = DataLoader(graph_pairs, batch_size=2, collate_fn=custom_collate_fn)\n",
    "\n",
    "# 遍历 DataLoader，输出 teacher 和 student 的批次\n",
    "for batch in loader:\n",
    "    print(\"Teacher batch:\")\n",
    "    print(batch[0])\n",
    "    print(\"Student batch:\")\n",
    "    print(batch[1])\n",
    "    print(\"-\" * 50)\n"
   ],
   "id": "7d046e07f4969e4c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher batch:\n",
      "DataBatch(x=[5, 1], edge_index=[2, 5], batch=[5], ptr=[3])\n",
      "Student batch:\n",
      "DataBatch(x=[5, 1], edge_index=[2, 4], batch=[5], ptr=[3])\n",
      "--------------------------------------------------\n",
      "Teacher batch:\n",
      "DataBatch(x=[4, 1], edge_index=[2, 4], batch=[4], ptr=[2])\n",
      "Student batch:\n",
      "DataBatch(x=[3, 1], edge_index=[2, 3], batch=[3], ptr=[2])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
